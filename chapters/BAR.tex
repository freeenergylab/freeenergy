% !TeX spellcheck = en_US
\subsection{Bennett Acceptance Ratio\label{Sec:FEM:BAR}}
\begin{chapquote}{Professor Savas Dimopoulos, Stanford University}
	``The thing that differentiates scientists is purely an artistic ability to discern what is a good idea, what is a beautiful idea, what is worth spending time on, and most importantly, what is a problem that is sufficiently interesting, yet sufficiently difficult, that is hasn't yet been solved, but the time for solving it has come now.''
\end{chapquote}
Bennett acceptance ratio was developed by Bennett in 1976,\cite{BennettJComputPhys1976} and was re-discovered by Crooks\cite{CrooksPRE2000} for Markovian and balanced dynamics and by Shirts et al\cite{ShirtsPRL2003} using maximum likelihood over 20 years later. The Metropolis function is defined as
\begin{equation}
	M(x)=min\{1,\exp{(-x)}\},
\end{equation}
which has the property 
\begin{equation}
	M(x)/M(-x)=\exp{(-x)}.
\end{equation}

If we make a trial move that keeps the same configuration ($q_{1},\cdots,q_{N}$)
but switches the potential function from $U_{0}$ to $U_{1}$ or vice-versa, 
the acceptance probabilities for such a pair of trial moves must satisfy
the detailed balance
\begin{equation}
	M(U_{1}-U_{0})\exp{(-U_{0})}=M(U_{0}-U_{1})\exp{(-U_{1})}.
\end{equation}

Integrating this identity over all of configuration space and multiplying
by the trivial factors $Q_{0}/Q_{0}$ and $Q_{1}/Q_{1}$, one obtains:

\begin{equation}
	Q_{0}\frac{\displaystyle\int M(U_{1}-U_{0})\exp{(-U_{0})}\diff\mathbf{{q}}}{Q_{0}}=Q_{1}\frac{\displaystyle\int M(U_{0}-U_{1})\exp{(-U_{1})}\diff\mathbf{{q}}}{Q_{1}},
\end{equation}
or simply

\begin{equation}
	\frac{Q_{0}}{Q_{1}}=\frac{\langle M(U_{0}-U_{1})\rangle_{1}}{\langle M(U_{1}-U_{0})\rangle_{0}}.\label{eq:FEM:BAR:MetropolisRatio}
\end{equation}

The physical meaning of this formula is that a Monte Carlo calculation
that includes potential-switching trial moves would distribute configurations
between $U_{1}$ and $U_{0}$ in the ratio of their configurational
integrals. 

A formula more general than Eq.~\ref{eq:FEM:BAR:MetropolisRatio} can be written as
\begin{equation}
	\frac{Q_{0}}{Q_{1}}=\frac{Q_{0}}{Q_{1}}\frac{\displaystyle\int W\exp{(-U_{0}-U_{1})}\diff\mathbf{{q}}}{\displaystyle\int W\exp{(-U_{1}-U_{0})}\diff\mathbf{{q}}}=\frac{\langle W\exp{(-U_{0})}\rangle_{1}}{\langle W\exp{(-U_{1})}\rangle_{0}},\label{eq:FEM:BAR:weightedratio}
\end{equation}
where $W$ is an arbitrary weighting function.

Optimization of the free energy estimate is most easily carried out in the limit of large sample sizes. Let the available data consist
of $n_{0}$ statistically independent configurations from the $U_{0}$ ensemble and $n_{1}$ from the $U_{1}$ ensemble, and let the data
be used in Eq.~\ref{eq:FEM:BAR:weightedratio} to obtain a finite-sample estimate of the reduced free energy difference $\Delta A=A_{1}-A_{0}=\ln{(Q_{0}/Q_{1})}$.
Using the error propagation law of uncorrelated variables ($covar(x_1,x_2)=0$),\cite{BerendsenBook2011}
\begin{equation}
	\delta^2\left[y(x_{1},x_{2})\right]=\left(\frac{\partial y}{\partial x_{1}}\right)^{2}\delta^2(x_{1})+\left(\frac{\partial y}{\partial x_{2}}\right)^{2}\delta^2(x_{2}).
\end{equation}

Thus we have the variance of $\Delta A$
\begin{eqnarray}
	\delta^2(\Delta A) & = & \left(\frac{\partial\Delta A}{\partial Q_{0}}\right)^{2}\delta^2Q_0+\left(\frac{\partial\Delta A}{\partial Q_{1}}\right)^{2}\delta^2Q_1\notag\\
	& = & \left(\frac{1}{Q_{0}}\right)^{2}\delta^2Q_0+\left(-\frac{1}{Q_{1}}\right)^{2}\delta^2Q_1\notag\\
	& = & \left(\frac{1}{Q_{0}}\right)^{2}\delta^2Q_0+\left(\frac{1}{Q_{1}}\right)^{2}\delta^2Q_1.
\end{eqnarray}

With the definition of variance $\delta^2X=\left\langle X^{2}\right\rangle -\left\langle X\right\rangle ^{2}$,
we have 
\begin{eqnarray}
	\delta^2Q_0 & = & \delta^2\left\langle W\exp{(-U_{0})}\right\rangle_{1}\notag\\
	& = & \delta^2\left(\frac{1}{n_1}\sum_{i=1}^{n_1}W_{i}\exp{\left(-U_{0}(i)\right)}\right)\notag\\
	& = & \sum_{i=1}^{n_{1}}\left(\frac{1}{n_{1}}\right)^{2}\delta^2\left(W_{i}\exp{\left(-U_{0}(i)\right)}\right)\notag\\
	& = & \frac{1}{n_{1}}\delta^2\left(W_{i}\exp{\left(-U_{0}(i)\right)}\right)\notag\\
	& = & \frac{1}{n_{1}}\left\{ \left< \left[W\exp{(-U_{0})}\right]^{2}\right>_{1}-\left[\left< W\exp{(-U_{0})}\right>_{1}\right]^{2}\right\}\notag\\
	& = & \frac{1}{n_{1}}\left\{ \left< W^{2}\exp{(-2U_{0})}\right>_{1}-\left[\left< W\exp{(-U_{0})}\right>_{1}\right]^{2}\right\},
\end{eqnarray}
which shows that the variance of the mean of the samples equals to the variance of the samples divided by the number of samples.

With sufficiently large sample sizes, the error of this estimate will
be nearly Gaussian, and its expected square is exactly the variance
of $\Delta A$ 
\begin{align}
	\delta^2 & (\Delta A_{est}-\Delta A)\nonumber \\
	\approx & \frac{\langle W^{2}\exp{(-2U_{1})}\rangle_{0}}{n_{0}[\langle W\exp{(-U_{1})}\rangle_{0}]^{2}}+\frac{\langle W^{2}\exp{(-2U_{0})}\rangle_{1}}{n_{1}[\langle W\exp{(-U_{0})}\rangle_{1}]^{2}}-\frac{1}{n_{0}}-\frac{1}{n_{1}}\nonumber \\
	= & \frac{\displaystyle\int\left[\frac{Q_{0}}{n_{0}}\exp{(-U_{1})}+\frac{Q_{1}}{n_{1}}\exp{(-U_{0})}\right]W^{2}\exp{(-U_{0}-U_{1})}\diff\mathbf{q}}{\left[\displaystyle\int W\exp{(-U_{0}-U_{1})}\diff\mathbf{q}\right]^{2}}\notag\\
	  &-\frac{1}{n_{0}}-\frac{1}{n_{1}}.\label{eq:FEM:BAR:expectation}
\end{align}

To minimize it with respect to $W$, we have
\begin{equation}
	W=const\times\left(\frac{Q_{0}}{n_{0}}\exp{(-U_{1})}+\frac{Q_{1}}{n_{1}}\exp{(-U_{0})}\right)^{-1}.
	\label{eq:FEM:BAR:W}
\end{equation}

Substituting this into Eq.~\ref{eq:FEM:BAR:weightedratio} yields
\begin{equation}
	\frac{Q_{0}}{Q_{1}}=\frac{\langle f(U_{0}-U_{1}+C)\rangle_{1}}{\langle f(U_{1}-U_{0}-C)\rangle_{0}}\exp{(+C)},
	\label{Eq:FEM:BAR:BAR}
\end{equation}
where
\begin{equation}
	C=\ln\frac{Q_{0}n_{1}}{Q_{1}n_{0}},
	\label{Eq:FEM:BAR:C}
\end{equation}
and $f$ denotes the Fermi function
\begin{equation}
	f(x)=\frac{1}{1+\exp{(+x)}}.
\end{equation}
It can also be expressed as\cite{ShirtsPRL2003}
\begin{equation}
	n_1\langle f(U_{0}-U_{1}+C)\rangle_{1}=n_0\langle f(U_{1}-U_{0}-C)\rangle_{0}.
\end{equation}
It should be noted that Eq.~\ref{Eq:FEM:BAR:BAR} is true for any $C$, which is actually a shift for one of the potential function. But the particular value specified in Eq.~\ref{Eq:FEM:BAR:C} minimizes the expected square error given the finite numbers ($n_0$ and $n_1$) of samples.

The variance of $\Delta A$ can be obtained by substituting Eq.~\ref{eq:FEM:BAR:W} into Eq.~\ref{eq:FEM:BAR:expectation}, and is 
\begin{align}
	\delta^2 \Delta A =&\frac{\left<f^2(U_{1}-U_{0}-C)\right>_0}{n_0\left<f(U_{1}-U_{0}-C)\right>_0^2}+\frac{\left<f^2(U_{0}-U_{1}+C)\right>_1}{n_1\left<f(U_{0}-U_{1}+C)\right>_1^2}-\frac{1}{n_0}-\frac{1}{n_1}\notag\\
	=&\left(\int \frac{n_0n_1\rho_0\rho_1}{n_0\rho_0+n_1\rho_1}\diff \mathbf{q}\right)^{-1}-\frac{n_0+n_1}{n_0n_1},
\end{align}
in which $\rho_i=\exp{(-U_i)}/Q_i$ is the probability.

It is worth emphasizing that Bennett acceptance ratio is asymptotically unbiased, and no other asymptotically unbiased estimator has lower asymptotic mean-squared error. However, it is not clear whether its behavior is always better than other estimators with finite sample sizes.

Shirts et al showed that BAR can be interpreted in terms of the maximum likelihood estimate of the free energy difference given a set of work values in the forward and reverse directions.\cite{ShirtsPRL2003} Starting from (refer to Appendix~\ref{chapter:Appendix:DeltaUDistributions} for the proof)
\begin{equation}
	\ln\left[\frac{P(W|F)}{P(-W|R)}\right]=\beta (W-\Delta F),
	\label{eq:FEM:BAR:distributionratio}
\end{equation}
where $P(W|F)$ ($P(W|R)$) is probability distribution for the work from the two states in the forward (reverse) direction, which can also be thought as the conditional probability of a work value given that it is a forward (reverse) measurement. To simplify the notation, the work $W$ from the reverse direction will be replaced by $-W$. Using the fact that $P(F|W)+P(R|W)=1$, the ratio can be rewritten as
\begin{equation}
	\frac{P(W|F)}{P(R|R)}=\frac{P(F|W)P(R)}{P(R|W)P(F)}=\frac{P(F|W)}{1-P(F|W)}\frac{P(R)}{P(F)}.
\end{equation}
It can be realized that $P(R)/P(F)=n_R/n_F$, where $n_F$ ($n_R$) is the number of forward (reverse) measurement. Defining $M=\ln{n_F/n_R}$, Eq.~\ref{eq:FEM:BAR:distributionratio} can be rewritten as
\begin{equation}
	\ln\frac{P(F|W)}{1-P(F|W)}=(M+W-\Delta F),
\end{equation}
which leads to
\begin{align}
	P(F|W_i)=&\frac{1}{1+\exp[-(M-W_i-\Delta F)]},\\
	P(R|W_i)=&\frac{1}{1+\exp[M-W_i-\Delta F]}
\end{align}
for a single work measurement $W_i$, given a value of the free energy difference $\Delta F$.

Given a value for $\Delta F$, the overall likelihood $L$ becomes
\begin{equation}
	L(\Delta F)=\prod_{i=1}^{n_F}P(F|W_i)\prod_{i=1}^{n_R}P(R|W_i).
\end{equation}
The most likely value of $\Delta F$ is the value that maximizes the (log) likelihood, therefore we have
\begin{align}
	0=\frac{\partial \log L(\Delta F)}{\partial \Delta F}=&-\sum_{i=1}^{n_F}\frac{1}{1+\exp\left[M+W_i-\Delta F\right]}\notag\\
	                                                      &+\sum_{j=1}^{n_R}\frac{1}{1+\exp\left[-(M+W_j-\Delta F)\right]},
\end{align}
which equivalent to the BAR method.